{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0bb6d8d0-6787-4b3a-99b9-f7791fab66e5",
   "metadata": {},
   "source": [
    "Import relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3fa77bf6-a81e-48e8-8ec2-01aa60bd81a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-31T20:05:37.663697Z",
     "iopub.status.busy": "2024-03-31T20:05:37.663226Z",
     "iopub.status.idle": "2024-03-31T20:05:37.665815Z",
     "shell.execute_reply": "2024-03-31T20:05:37.665473Z",
     "shell.execute_reply.started": "2024-03-31T20:05:37.663680Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "import pyspark.sql.types as T\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c1fca1-5c01-47bb-b397-dd32048d9c40",
   "metadata": {},
   "source": [
    "Create a spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1aacb0c2-1975-4faf-a934-38a6bf93e21a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-31T17:54:31.307681Z",
     "iopub.status.busy": "2024-03-31T17:54:31.307283Z",
     "iopub.status.idle": "2024-03-31T17:54:37.245024Z",
     "shell.execute_reply": "2024-03-31T17:54:37.244551Z",
     "shell.execute_reply.started": "2024-03-31T17:54:31.307664Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/03/31 13:54:35 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"add_TF\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6fc160-bedb-4f33-b6ec-9b32f5fb4b73",
   "metadata": {},
   "source": [
    "Pick the chromosome to process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3a727a1-1dee-4a4a-b7ba-62b8d1bdf751",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-31T17:54:37.246188Z",
     "iopub.status.busy": "2024-03-31T17:54:37.245962Z",
     "iopub.status.idle": "2024-03-31T17:54:37.249003Z",
     "shell.execute_reply": "2024-03-31T17:54:37.248650Z",
     "shell.execute_reply.started": "2024-03-31T17:54:37.246172Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "only crunching chromosome chr22\n"
     ]
    }
   ],
   "source": [
    "chromosome=\"NONE\"\n",
    "\n",
    "\n",
    "if \"which_chr\" in os.environ:\n",
    "    chromosome = os.environ['which_chr']\n",
    "\n",
    "if chromosome==\"NONE\":\n",
    "    print(\"error : did not find which chromosome we are supposed to crunch!\")\n",
    "    exit(-1)\n",
    "else:\n",
    "    print(\"only crunching chromosome \"+chromosome)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad08c2f7-80a6-41ae-ae8a-71bb35665544",
   "metadata": {},
   "source": [
    "Load the chromosome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b7360fa-7209-426c-bc50-dbc88b1d4c8f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-31T17:54:37.249715Z",
     "iopub.status.busy": "2024-03-31T17:54:37.249492Z",
     "iopub.status.idle": "2024-03-31T17:54:55.358310Z",
     "shell.execute_reply": "2024-03-31T17:54:55.357784Z",
     "shell.execute_reply.started": "2024-03-31T17:54:37.249701Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/31 13:54:49 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "variant_path=f\"/gpfs/gibbs/pi/reilly/VariantEffects/scripts/noon_data/3.0pleio_and_filter/{chromosome}/*.csv.gz\"\n",
    "\n",
    "variants=spark.read.option(\"delimiter\",\"\\t\") \\\n",
    "    .csv(variant_path, header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7e303ebd-085b-47dd-ab27-0402a022e4ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-31T20:34:51.705232Z",
     "iopub.status.busy": "2024-03-31T20:34:51.704785Z",
     "iopub.status.idle": "2024-03-31T20:34:51.709285Z",
     "shell.execute_reply": "2024-03-31T20:34:51.708953Z",
     "shell.execute_reply.started": "2024-03-31T20:34:51.705215Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[CHROM: string, POS: int, ID: string, REF: string, ALT: string, QUAL: string, FILTER: string, INFO: string, K562__ref: double, HepG2__ref: double, SKNSH__ref: double, K562__alt: double, HepG2__alt: double, SKNSH__alt: double, K562__skew: double, HepG2__skew: double, SKNSH__skew: double, AC: int, AN: int, AF: double, cadd_phred: double, is_in_dELS: boolean, is_in_CA: boolean, is_in_pELS: boolean, is_in_CA-H3K4me3: boolean, is_in_CA-CTCF: boolean, is_in_PLS: boolean, is_in_TF: boolean, is_in_CA-TF: boolean, P_ANNO: double, mean_ref: double, mean_skew: double, MAF: double, category: string, emVar_K562: boolean, emVar_SKNSH: boolean, emVar_HepG2: boolean, pleio: int]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variants"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4b0090-08ce-4bf3-be23-77bf1c28a5c9",
   "metadata": {},
   "source": [
    "Load the TF file.\n",
    "\n",
    "File from Dr. Steven Rong, \n",
    "TEMP: see slack #var-eff-reilly, 2024-03-13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4f02b8e4-5589-4855-8ed1-bb0ff89dfbdf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-31T20:16:33.650808Z",
     "iopub.status.busy": "2024-03-31T20:16:33.650361Z",
     "iopub.status.idle": "2024-03-31T20:16:33.789482Z",
     "shell.execute_reply": "2024-03-31T20:16:33.789069Z",
     "shell.execute_reply.started": "2024-03-31T20:16:33.650792Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tf_footprint_path=\"/gpfs/gibbs/pi/reilly/VariantEffects/scripts/noon_data/consensus_footprints_and_motifs_hg38_GRanges.txt.gz\"\n",
    "\n",
    "tf_footprints=spark.read.option(\"delimiter\", \"\\t\").csv(tf_footprint_path, header=True, inferSchema=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b439c29-090c-4f7c-b824-3534628adfb4",
   "metadata": {},
   "source": [
    "Our variant file (the chromosome we just loaded) was originally a VCF, which is 1-based.\n",
    "\n",
    "Is our TF footprint file 0 or 1 based? I would *guess* 0-based, since it is bed-y.\n",
    "\n",
    "Recall:\n",
    "\n",
    "```\n",
    "ChrZ        T   A   C   G   T\n",
    "          | | | | | | | | | |\n",
    "1 based   | 1 | 2 | 3 | 4 | 5\n",
    "0 based   0   1   2   3   4\n",
    "```\n",
    "\n",
    "1 based vs 1-based\n",
    "\n",
    "By inspection, we see,\n",
    "\n",
    "1-based : length=end-start+1\n",
    "0-based : length=end-start\n",
    "\n",
    "\n",
    "Our first two rows have:\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "seqnames        start   end     width   strand  identifier      mean_signal     num_samples     num_fps summitcore_start       core_end        motif_clusters\n",
    "chr1    180788  180831  44      *       1.100643.4      92.527889       6       6       180802  180784  180808RREB1_MA0073.1;RREB1_MA0073.1;RREB1_MA0073.1;RARA_MOUSE.H11MO.0.A;TBX1_TBX_1;RR\\\n",
    "EB1_MA0073.1;ZNF524_C2H2_1;TBX20_TBX_1;TBX20_TBX_5;RARA+RXRG_MA1149.1;RREB1_MA0073.1;RREB1_MA0073.1;RREB1_MA0073.1;RREB1_MA0073.1;RREB1_MA0073.1\n",
    "\n",
    "```\n",
    "\n",
    "The formtting here is a little weird. 'seqnames' seems to refer to chromosome.\n",
    "\n",
    "end-start=180831-180788=43\n",
    "\n",
    "end-start+1 = 43+1 = width\n",
    "\n",
    "So it's 1-based.\n",
    "\n",
    "intersection : vcf_coord>=start && vcf_coord <= end\n",
    "\n",
    "easy!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af82981b-5c08-437e-9544-cc10b12ce303",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-31T19:43:15.333498Z",
     "iopub.status.busy": "2024-03-31T19:43:15.333031Z",
     "iopub.status.idle": "2024-03-31T19:43:15.336521Z",
     "shell.execute_reply": "2024-03-31T19:43:15.336183Z",
     "shell.execute_reply.started": "2024-03-31T19:43:15.333481Z"
    },
    "tags": []
   },
   "source": [
    "Cast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "431601cd-406e-48f7-a8d2-9e8ac80593a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-31T20:16:47.166786Z",
     "iopub.status.busy": "2024-03-31T20:16:47.166362Z",
     "iopub.status.idle": "2024-03-31T20:16:47.190360Z",
     "shell.execute_reply": "2024-03-31T20:16:47.189981Z",
     "shell.execute_reply.started": "2024-03-31T20:16:47.166769Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "int_columns = [\"start\", \"end\"]\n",
    "\n",
    "# Cast integer columns\n",
    "for column in int_columns:\n",
    "    tf_footprints = tf_footprints.withColumn(column, F.col(column).cast(T.IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4a9b92a8-192f-4e8f-bdf1-05e8c84d1c73",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-31T20:16:52.728654Z",
     "iopub.status.busy": "2024-03-31T20:16:52.728207Z",
     "iopub.status.idle": "2024-03-31T20:16:52.732267Z",
     "shell.execute_reply": "2024-03-31T20:16:52.731949Z",
     "shell.execute_reply.started": "2024-03-31T20:16:52.728638Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[seqnames: string, start: int, end: int, width: string, strand: string, identifier: string, mean_signal: string, num_samples: string, num_fps: string, summit: string, core_start: string, core_end: string, motif_clusters: string]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_footprints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d414b32-0385-4213-ad0e-0e968f61dd1a",
   "metadata": {},
   "source": [
    "Subset the dataframe to the relevant portion. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a90acf1c-84a3-4199-8ef1-aea79be4c10c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-31T20:25:27.390952Z",
     "iopub.status.busy": "2024-03-31T20:25:27.390730Z",
     "iopub.status.idle": "2024-03-31T20:25:27.407349Z",
     "shell.execute_reply": "2024-03-31T20:25:27.406969Z",
     "shell.execute_reply.started": "2024-03-31T20:25:27.390937Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# List of columns I want to keep\n",
    "columns_to_keep = [\"seqnames\", \"start\", \"end\"]\n",
    "\n",
    "tf_footprints = tf_footprints.select(*columns_to_keep).filter(tf_footprints[\"seqnames\"] == chromosome)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "239635de-1675-4cfe-a317-5fd9bdb94121",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-31T20:31:12.769028Z",
     "iopub.status.busy": "2024-03-31T20:31:12.768633Z",
     "iopub.status.idle": "2024-03-31T20:31:12.775230Z",
     "shell.execute_reply": "2024-03-31T20:31:12.774883Z",
     "shell.execute_reply.started": "2024-03-31T20:31:12.769013Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tf_footprints_broadcast = F.broadcast(tf_footprints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "49c24336-b2fc-4837-8285-165adb22d558",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-31T20:35:18.464220Z",
     "iopub.status.busy": "2024-03-31T20:35:18.463809Z",
     "iopub.status.idle": "2024-03-31T20:35:18.482147Z",
     "shell.execute_reply": "2024-03-31T20:35:18.481762Z",
     "shell.execute_reply.started": "2024-03-31T20:35:18.464204Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#employing a simple strategy where we make a table with every TF range\n",
    "#in a row with every (cartesian product) then just delete those that don't fall in \n",
    "#the range. This is algorithmically boneheaded (much better algo exist w/ better time complexity), \n",
    "#but since one of the tables is small we can broadcast is which is fast. \n",
    "#so it works fine. \n",
    "joined_df = variants.crossJoin(tf_footprints_broadcast) \\\n",
    "    .filter((F.col(\"POS\") >= F.col(\"start\")) & (F.col(\"POS\") <= F.col(\"end\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5cc4b274-b553-4d60-9d79-2b8410211a2c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-31T20:56:04.414827Z",
     "iopub.status.busy": "2024-03-31T20:56:04.414557Z",
     "iopub.status.idle": "2024-03-31T20:56:04.424360Z",
     "shell.execute_reply": "2024-03-31T20:56:04.423964Z",
     "shell.execute_reply.started": "2024-03-31T20:56:04.414811Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#now we simply select those positions that did fall in a TF\n",
    "pos_in_TF = joined_df.select(\"POS\").distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c7c99579-fe90-4527-b001-b1bbdfba6c3b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-31T20:56:04.986489Z",
     "iopub.status.busy": "2024-03-31T20:56:04.986242Z",
     "iopub.status.idle": "2024-03-31T20:56:05.024865Z",
     "shell.execute_reply": "2024-03-31T20:56:05.024450Z",
     "shell.execute_reply.started": "2024-03-31T20:56:04.986474Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#and annotate the original variants dataframe with that information\n",
    "\n",
    "#add a simple TRUE for variants in at TF motif\n",
    "pos_in_TF = pos_in_TF.withColumn(\"in_TF\", F.lit(True))\n",
    "\n",
    "variants_annotated = variants.join(pos_in_TF, on=\"POS\", how=\"left\")\n",
    "\n",
    "#those positions not found to be in any interval shold be false!\n",
    "variants_annotated = variants_annotated.fillna({'in_TF': False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12c69a8-59b0-4ed9-954b-6a3d63478f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dump the data back to disc. \n",
    "output_root=\"/home/mcn26/varef/scripts/noon_data/3.5add_TF_footprints/\"\n",
    "\n",
    "variants_annotated.write \\\n",
    "    .option(\"header\",\"true\") \\\n",
    "    .option(\"delimiter\",\"\\t\") \\\n",
    "    .option(\"compression\", \"gzip\") \\\n",
    "    .csv(output_root+chromosome)\n",
    "\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
