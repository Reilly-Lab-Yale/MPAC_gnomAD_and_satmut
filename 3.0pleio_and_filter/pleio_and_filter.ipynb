{
  "cells": [
    {
      "outputs": [],
      "metadata": {
        "execution": {
          "shell.execute_reply.started": "2024-02-15T20:45:39.381961Z",
          "iopub.status.idle": "2024-02-15T20:45:39.384135Z",
          "iopub.status.busy": "2024-02-15T20:45:39.381566Z",
          "iopub.execute_input": "2024-02-15T20:45:39.381978Z",
          "shell.execute_reply": "2024-02-15T20:45:39.383776Z"
        },
        "tags": []
      },
      "execution_count": 4,
      "source": "from pyspark.sql import SparkSession\nfrom pyspark.sql import functions as F\nimport os",
      "id": "6c3c2d11-f4e5-4416-b5c1-e753ca783623",
      "cell_type": "code"
    },
    {
      "source": "spark = SparkSession.builder.appName(\"pleio_and_filter\").getOrCreate()",
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Setting default log level to \"WARN\".\n",
            "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
            "24/02/15 15:44:26 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
            "24/02/15 15:44:40 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\n"
          ],
          "name": "stderr"
        }
      ],
      "execution_count": 2,
      "cell_type": "code",
      "id": "35c6c4ae-70d4-4a8f-9fda-56bbec002988",
      "metadata": {
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-02-15T20:44:21.725949Z",
          "iopub.execute_input": "2024-02-15T20:44:21.726527Z",
          "shell.execute_reply": "2024-02-15T20:44:27.794692Z",
          "iopub.status.idle": "2024-02-15T20:44:27.795150Z",
          "shell.execute_reply.started": "2024-02-15T20:44:21.726509Z"
        }
      }
    },
    {
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "only crunching chromosome chr22\n"
          ],
          "name": "stdout"
        }
      ],
      "id": "eb39af83-e420-4c1b-9820-59c1622f7eb0",
      "metadata": {
        "tags": [],
        "execution": {
          "shell.execute_reply.started": "2024-02-15T20:47:23.775516Z",
          "iopub.status.idle": "2024-02-15T20:47:23.778360Z",
          "shell.execute_reply": "2024-02-15T20:47:23.778016Z",
          "iopub.status.busy": "2024-02-15T20:47:23.775259Z",
          "iopub.execute_input": "2024-02-15T20:47:23.775534Z"
        }
      },
      "source": "chromosome=\"NONE\"\n#chromosome=\"chr22\"\n\nif \"which_chr\" in os.environ:\n    chromosome=os.environ['which_chr']\n\nif chromosome==\"NONE\":\n    print(\"error : did not find which chromosome we are supposed to crunch\")\n    exit(-1)\nelse:\n    print(\"only crunching chromosome \"+chromosome)",
      "execution_count": 6,
      "cell_type": "code"
    },
    {
      "outputs": [
        {
          "text": [
            "                                                                                \r"
          ],
          "output_type": "stream",
          "name": "stderr"
        }
      ],
      "id": "8a25fe38-6591-43ee-822c-4ab4d0305cde",
      "source": "variant_path=f\"/home/mcn26/varef/scripts/noon_data/2.0.annotate/annotated_output_{chromosome}.csv.gz/*.csv.gz\"\nvariants=spark.read.option(\"delimiter\",\"\\t\").csv(variant_path, header=True, inferSchema=True)",
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-02-15T21:05:50.284007Z",
          "shell.execute_reply": "2024-02-15T21:06:05.290124Z",
          "shell.execute_reply.started": "2024-02-15T21:05:50.284239Z",
          "iopub.status.idle": "2024-02-15T21:06:05.290519Z",
          "iopub.execute_input": "2024-02-15T21:05:50.284254Z"
        }
      }
    },
    {
      "id": "cd93558c-ec67-4e4e-a0bd-9f114675d2c1",
      "cell_type": "markdown",
      "source": "## Dropping columns with bad allele frequencies",
      "metadata": {}
    },
    {
      "id": "a52dfadc-e353-4a0d-bab0-dce575da134c",
      "execution_count": 14,
      "cell_type": "code",
      "source": "variants=variants.filter(F.col(\"category\")!=\"MAF_OR_AC_IS_ZERO\")",
      "outputs": [],
      "metadata": {
        "tags": [],
        "execution": {
          "iopub.execute_input": "2024-02-15T21:06:05.291597Z",
          "iopub.status.busy": "2024-02-15T21:06:05.291271Z",
          "shell.execute_reply.started": "2024-02-15T21:06:05.291582Z",
          "iopub.status.idle": "2024-02-15T21:06:05.297480Z",
          "shell.execute_reply": "2024-02-15T21:06:05.297158Z"
        }
      }
    },
    {
      "source": "## Pleitropy\n\n\"Pleitropy\" here refers to a variant which is an emVar in multiple cell-types. We're calling emVars as anything with abs(skew)>=0.5 and max(alt activitym ref activity)>=1",
      "id": "7d7e2951-0f5b-45e5-b6e0-9a2a5fff4612",
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-02-15T21:06:05.298028Z",
          "iopub.execute_input": "2024-02-15T21:06:05.298179Z",
          "shell.execute_reply.started": "2024-02-15T21:06:05.298167Z",
          "iopub.status.idle": "2024-02-15T21:06:05.368764Z",
          "shell.execute_reply": "2024-02-15T21:06:05.368367Z"
        }
      },
      "execution_count": 15,
      "outputs": [],
      "source": "#first we compute whether each variant can be called an emvar in each cell-type. \ncell_types=[\"K562\",\"SKNSH\",\"HepG2\"]\nfor cell_type in cell_types:\n    variants = variants.withColumn(f\"emVar_{cell_type}\", \n                           (F.abs(F.col(f\"{cell_type}__skew\")) >= 0.5) & \n                           (F.greatest(F.col(f\"{cell_type}__ref\"), F.col(f\"{cell_type}__alt\")) >= 1.0))\n\n#next, we count the number of cell-types each variant is an emvar in to compute the pleitropy. \nvariants = variants.withColumn(\"pleio\", F.col(\"emVar_K562\").cast(\"int\") + F.col(\"emVar_SKNSH\").cast(\"int\") + F.col(\"emVar_HepG2\").cast(\"int\"))",
      "id": "86aed913-b16d-4e67-83b3-a515a97973d5"
    },
    {
      "cell_type": "code",
      "source": "output_root=\"/home/mcn26/varef/scripts/noon_data/3.0pleio_and_filter/\"\n\nvariants.write \\\n    .option(\"header\",\"true\") \\\n    .option(\"delimiter\",\"\\t\") \\\n    .option(\"compression\", \"gzip\") \\\n    .csv(output_root+chromosome)\n\nspark.stop()",
      "outputs": [],
      "execution_count": null,
      "metadata": {},
      "id": "b4cbe50b-9d29-4708-a97d-cd33bf748a5e"
    }
  ],
  "metadata": {
    "language_info": {
      "nbconvert_exporter": "python",
      "mimetype": "text/x-python",
      "pygments_lexer": "ipython3",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      },
      "file_extension": ".py",
      "name": "python",
      "version": "3.10.12"
    },
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3 (ipykernel)",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}