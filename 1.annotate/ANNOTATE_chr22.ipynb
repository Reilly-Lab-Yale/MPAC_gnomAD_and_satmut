{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b616ec91-60ec-4a6b-acf0-10276eb6a069",
   "metadata": {},
   "source": [
    "This notebook annotates all gnomad variants with their corresponding malinouis predictions, the phyloP scores associated with their genomic locations, and the genomic regions (enhancer or not) they fall within. \n",
    "\n",
    "(Execute notebook after crunching wig into csv, as per other file)\n",
    "\n",
    "Import relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee846e1e-6265-45e6-8b6b-1b11261fdd1f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T20:12:06.087083Z",
     "iopub.status.busy": "2023-12-04T20:12:06.086578Z",
     "iopub.status.idle": "2023-12-04T20:12:06.089548Z",
     "shell.execute_reply": "2023-12-04T20:12:06.089157Z",
     "shell.execute_reply.started": "2023-12-04T20:12:06.087064Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, FloatType\n",
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11021805-1df7-4ba6-99e8-28cf49efab35",
   "metadata": {},
   "source": [
    "Create spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae2690fc-67a5-4da4-a561-1dbb9a77a923",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T20:12:07.973683Z",
     "iopub.status.busy": "2023-12-04T20:12:07.973224Z",
     "iopub.status.idle": "2023-12-04T20:12:10.342233Z",
     "shell.execute_reply": "2023-12-04T20:12:10.341752Z",
     "shell.execute_reply.started": "2023-12-04T20:12:07.973666Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/12/04 15:12:09 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "23/12/04 15:12:09 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "if 'spark' in locals() and spark!=None:\n",
    "    spark.stop()\n",
    "\n",
    "    #are we running the actual script, or just testing?\n",
    "for_real=True\n",
    "\n",
    "spark=None\n",
    "\n",
    "if for_real:\n",
    "    #Should run in 300GB memory & 24 cores\n",
    "    #give it more to be safe\n",
    "    spark = SparkSession.builder \\\n",
    "        .appName(\"ANNOTATE\") \\\n",
    "        .config(\"spark.executor.instances\", \"4\") \\\n",
    "        .config(\"spark.executor.cores\", \"5\") \\\n",
    "        .config(\"spark.executor.memory\", \"50g\") \\\n",
    "        .config(\"spark.driver.memory\", \"30g\") \\\n",
    "        .config(\"spark.driver.cores\", \"3\") \\\n",
    "        .config(\"spark.executor.memoryOverhead\", \"70g\") \\\n",
    "        .getOrCreate()\n",
    "    \n",
    "    #assuming 3tb memory & 24 cores\n",
    "    #spark = SparkSession.builder \\\n",
    "    #    .appName(\"ANNOTATE\") \\\n",
    "    #    .config(\"spark.executor.instances\", \"4\") \\\n",
    "    #    .config(\"spark.executor.cores\", \"5\") \\\n",
    "    #    .config(\"spark.executor.memory\", \"710g\") \\\n",
    "    #    .config(\"spark.driver.memory\", \"30g\") \\\n",
    "    #    .config(\"spark.driver.cores\", \"3\") \\\n",
    "    #    .config(\"spark.executor.memoryOverhead\", \"70g\") \\\n",
    "    #    .config(\"spark.sql.shuffle.partitions\", \"1000\") \\\n",
    "    #    .config(\"spark.shuffle.manager\", \"sort\") \\\n",
    "    #    .config(\"spark.driver.extraJavaOptions\", \"-XX:+UseG1GC\") \\\n",
    "    #    .config(\"spark.executor.extraJavaOptions\", \"-XX:+UseG1GC\") \\\n",
    "    #    .getOrCreate()\n",
    "else:\n",
    "    spark = SparkSession.builder \\\n",
    "        .appName(\"ANNOTATE_TEST\") \\\n",
    "        .config(\"spark.executor.memory\", \"4g\") \\\n",
    "        .config(\"spark.driver.memory\", \"4g\") \\\n",
    "        .config(\"spark.sql.shuffle.partitions\", \"10\") \\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "522ce39d-ca21-4afe-85dd-0dbe89dea6e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T20:12:15.259216Z",
     "iopub.status.busy": "2023-12-04T20:12:15.258913Z",
     "iopub.status.idle": "2023-12-04T20:12:15.263593Z",
     "shell.execute_reply": "2023-12-04T20:12:15.263195Z",
     "shell.execute_reply.started": "2023-12-04T20:12:15.259196Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://r814u23n04.mccleary.ycrc.yale.edu:4041\n"
     ]
    }
   ],
   "source": [
    "print(spark.sparkContext.uiWebUrl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9970c4b9-2069-407a-9ca4-781abfca2914",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T20:12:16.668744Z",
     "iopub.status.busy": "2023-12-04T20:12:16.668280Z",
     "iopub.status.idle": "2023-12-04T20:12:18.284415Z",
     "shell.execute_reply": "2023-12-04T20:12:18.283981Z",
     "shell.execute_reply.started": "2023-12-04T20:12:16.668726Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "#define the phylop tsv schema\n",
    "phylop_schema = StructType([\n",
    "    StructField(\"CHROM\", StringType(), True),\n",
    "    StructField(\"POS\", IntegerType(), True),\n",
    "    StructField(\"P_ANNO\", FloatType(), True),\n",
    "])\n",
    "\n",
    "#read in the phylop tsv\n",
    "phylop_anno = spark.read \\\n",
    "    .option(\"comment\", \"#\") \\\n",
    "    .option(\"delimiter\", \"\\t\") \\\n",
    "    .schema(phylop_schema) \\\n",
    "    .csv(\"/home/mcn26/varef/scripts/noon_data/1.annotate/out_processed.tsv\", header=False)\n",
    "\n",
    "#define the big boy vcf schema\n",
    "vcf_schema = StructType([\n",
    "    StructField(\"CHROM\", StringType(), True),\n",
    "    StructField(\"POS\", IntegerType(), True),\n",
    "    StructField(\"ID\", StringType(), True),\n",
    "    StructField(\"REF\", StringType(), True),\n",
    "    StructField(\"ALT\", StringType(), True),\n",
    "    StructField(\"QUAL\", StringType(), True),\n",
    "    StructField(\"FILTER\", StringType(), True),\n",
    "    StructField(\"INFO\", StringType(), True),\n",
    "\n",
    "])\n",
    "\n",
    "#read in the vcf data\n",
    "vcf = spark.read \\\n",
    "    .option(\"comment\", \"#\") \\\n",
    "    .option(\"delimiter\", \"\\t\") \\\n",
    "    .schema(vcf_schema) \\\n",
    "    .csv(\"/home/mcn26/varef/scripts/noon_data/0.merge/out/*.vcf.gz\", header=False)\n",
    "\n",
    "\n",
    "#define genomic region annotation (bed file) schema\n",
    "bed_schema = StructType([\n",
    "    StructField(\"CHROM\", StringType(), True),\n",
    "    StructField(\"START\", IntegerType(), True),\n",
    "    StructField(\"STOP\", StringType(), True),\n",
    "])\n",
    "\n",
    "#load the encode enhancer datasets\n",
    "\n",
    "CRE_BASEPATH=\"/home/mcn26/varef/data/ENCODE/SCREEN_v4_cCREs_agnostic/\"\n",
    "\n",
    "promoters=spark.read \\\n",
    "    .schema(bed_schema) \\\n",
    "    .option(\"delimiter\", \"\\t\") \\\n",
    "    .csv(CRE_BASEPATH+\"GRCh38-PLS.V4.bed.gz\")\n",
    "\n",
    "\n",
    "prox_enhancers=spark.read \\\n",
    "    .schema(bed_schema) \\\n",
    "    .option(\"delimiter\", \"\\t\") \\\n",
    "    .csv(CRE_BASEPATH+\"GRCh38-pELS.V4.bed.gz\")\n",
    "\n",
    "distal_enhancers=spark.read \\\n",
    "    .schema(bed_schema) \\\n",
    "    .option(\"delimiter\", \"\\t\") \\\n",
    "    .csv(CRE_BASEPATH+\"GRCh38-dELS.V4.bed.gz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1bd36e-c5d0-47e4-acdd-329b6d5d885d",
   "metadata": {},
   "source": [
    "Just for testing : remove all variants not on chromosome 22."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3808325-39d8-4c5a-b746-a98511d59327",
   "metadata": {},
   "outputs": [],
   "source": [
    "vcf = vcf.filter(col(\"CHROM\") == \"chr22\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc577c9-6f52-4942-a342-1f465285745d",
   "metadata": {},
   "source": [
    "Add the genomic region annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c98be64d-19f3-4925-a49a-6145a3d2e96c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T20:12:23.375086Z",
     "iopub.status.busy": "2023-12-04T20:12:23.374590Z",
     "iopub.status.idle": "2023-12-04T20:12:23.378310Z",
     "shell.execute_reply": "2023-12-04T20:12:23.377913Z",
     "shell.execute_reply.started": "2023-12-04T20:12:23.375068Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_genomic_annotation(loci,regions,name):\n",
    "    \n",
    "\n",
    "    # as usual, we have to worry about coordinate systems\n",
    "    # VCFs are 1-based\n",
    "    # BEDs are 0-based\n",
    "    # Chr1        T   A   C   G   T\n",
    "    #           | | | | | | | | | |\n",
    "    # 1 based   | 1 | 2 | 3 | 4 | 5\n",
    "    # 0 based   0   1   2   3   4\n",
    "\n",
    "    result = loci.join(\n",
    "        regions,\n",
    "        (loci.CHROM == regions.CHROM) & \n",
    "        (loci.POS > regions.START) & \n",
    "        (loci.POS <= regions.STOP),\n",
    "        how='left'\n",
    "    )\n",
    "\n",
    "    # Add a boolean column 'is_in_region'\n",
    "    result = result.withColumn(\"is_in_\"+name, col(\"start\").isNotNull())\n",
    "\n",
    "    # Select only columns from df_loci and the new boolean column\n",
    "    final_result = result.select(loci[\"*\"], \"is_in_\"+name)\n",
    "    \n",
    "    return final_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c43c6be7-3856-4473-9b9e-82d8c3ec5bbf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T20:12:27.066897Z",
     "iopub.status.busy": "2023-12-04T20:12:27.066408Z",
     "iopub.status.idle": "2023-12-04T20:12:27.282744Z",
     "shell.execute_reply": "2023-12-04T20:12:27.282262Z",
     "shell.execute_reply.started": "2023-12-04T20:12:27.066880Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/12/04 15:12:27 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\n"
     ]
    }
   ],
   "source": [
    "genomic_regions_added=add_genomic_annotation(loci=vcf,regions=promoters,name=\"promoter\")\n",
    "genomic_regions_added=add_genomic_annotation(loci=genomic_regions_added,regions=prox_enhancers,name=\"prox_enhancers\")\n",
    "genomic_regions_added=add_genomic_annotation(loci=genomic_regions_added,regions=distal_enhancers,name=\"distal_enhancers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39a8b8c-c85d-4bcc-806a-74d941566215",
   "metadata": {},
   "source": [
    "Add the phyloP annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ebf30b3-0042-4a9d-a028-236ef1261fe8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T20:12:29.884694Z",
     "iopub.status.busy": "2023-12-04T20:12:29.884209Z",
     "iopub.status.idle": "2023-12-04T20:12:29.904925Z",
     "shell.execute_reply": "2023-12-04T20:12:29.904446Z",
     "shell.execute_reply.started": "2023-12-04T20:12:29.884676Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "phyloP_annotated = genomic_regions_added.join(phylop_anno, on=[\"CHROM\", \"POS\"], how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "423e7147-33ab-40f2-bcc0-9ed86050f6b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-30T22:39:37.732658Z",
     "iopub.status.busy": "2023-11-30T22:39:37.732367Z",
     "iopub.status.idle": "2023-11-30T23:23:36.065906Z",
     "shell.execute_reply": "2023-11-30T23:23:36.065311Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/11/30 17:39:45 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\n",
      "                                                                                                                                                                                    \r"
     ]
    }
   ],
   "source": [
    "phyloP_annotated.write.csv(\"/home/mcn26/varef/scripts/noon_data/1.annotate/annotated_output_chr22_only.csv\", header=True, mode=\"overwrite\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
